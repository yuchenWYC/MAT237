\documentclass[11pt]{article}

% Libraries.
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{perpage}
\usepackage{float}

% Property settings.
\MakePerPage{footnote}
\pagestyle{fancy}
\lhead{Notes by YW, TX}

% Commands
\newcommand{\ti}[1]{\textit{#1}}
\newcommand{\tb}[1]{\textbf{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\bx}[0]{\mathbf{x}}
\newcommand{\bv}[0]{\mathbf{v}}
\newcommand{\bw}[0]{\mathbf{w}}
\newcommand{\real}[0]{\mathbb{R}}
\newcommand{\under}[1]{\underline{#1}}
\newcommand{\proof}[0]{\textit{\underline{proof:} }}
\newcommand{\func}[3]{\tb{#1}: {#2} \rightarrow {#3} }

% Attr.
\title{MAT237 Multivariable Calculus \\ Lecture Notes}
\author{Yuchen Wang, Tingfeng Xia}
\date{\today}

\begin{document}
    \maketitle
    \tableofcontents
    \newpage
\section{Taylor's Theorem}
\subsection{Review of Taylor's Theorem in 1 Dimenson}
\paragraph{Definition of Taylor polynomials} Assume $I \subset \real$ is an open interval and that $f: I \rightarrow \real$ is a function of class $C^k$ on $I$.

For a point $a\in I$, the $kth$ order Taylor polynomial of $f$ at $a$ is the unique polynomial of order at most $k$, denoted$P_{a,k}(h)$ such that
\begin{align*}
    f(a) &= P_{a,k}(0)\\
    f'(a) &= P'_{a,k}(0)\\
    \vdots\\
    f^{(k)}(a) &= P_{a,k}^{(k)}(0)
\end{align*}
\begin{align*}
    P_{a,k}(h) &= f(a) + hf'(a) + \frac{h^2}{2}f"(a) +...+\frac{h^k}{k!}f^{(k)}(a)\\
    &= \sum_{j=0}^{k}\frac{h^j}{j!}f^{(j)}(a)
\end{align*}
\paragraph{Remark}
Taylor's Theorem guarantees that $P_{a,k}(h)$ is a very good approximation of $f(a+h)$, and that the quality of the approximation increases as $k$ increases.
\paragraph{Taylor's Theorem in 1D}Assume $I \subset \real$ is an open interval and that $f: I \rightarrow \real$ is a function of class $C^k$ on $I$. For $a \in I$ and $h \in \real$ such that $a+h\in I$, let $P_{a,k}(h)$ denote the $k$th-order Taylor polynomial at $a$ and define the remainder
$$R_{a,k}(h) := f(a+h) - P_{a,k}(h)$$
Then $$\lim_{h\rightarrow0}\frac{R_{a,k}(h)}{h^k} = 0$$

\subsection{Taylor's Theorem in higher dimensions}
Assume $S \subset \real^n$ is an open set and that $f: S \rightarrow \real$ is a function of class $C^k$ on $S$. For a point $a\in S$, the $kth$ order Taylor polynomial of $f$ at $a$ is the unique polynomial of order at most $k$, denoted$P_{a,k}(\tb{h})$ such that
\begin{align*}
    f(\tb{a}) &= P_{\tb{a},k}(\tb{0}) \\
    \partial^\alpha f(\tb{a}) &= \partial^\alpha P_{\tb{a},k}(\tb{0})
\end{align*}
for all partial derivatives of order up to $k$.

\paragraph{Taylor's Theorem in nD}Assume $S \subset \real^n$ is an open interval and that $f: S \rightarrow \real$ is a function of class $C^k$ on $I$. For $a \in S$ and $h \in \real^n$ such that $a+h\in S$, let $P_{a,k}(h)$ denote the $k$th-order Taylor polynomial at $a$ and define the remainder
$$R_{a,k}(h) := f(a+h) - P_{a,k}(h)$$
Then $$\lim_{h\rightarrow0}\frac{R_{a,k}(h)}{|h|^k} = 0$$

\paragraph{A Taylor polynomial formula for k = 2}
\begin{equation*}
P_{\tb{a},2}(\tb{h}) = f(\tb{a}) + \nabla f(\tb{a})\cdot \tb{h} + \frac{1}{2}(H(\tb{a})\tb{h})\cdot \tb{h}
\end{equation*}
where we remember that $\tb{h} = \tb{x} - \tb{a}$ if we want the result in terms of $x,y$. 
%As a result, $$\lim_{h\rightarrow0}\frac{R_{a,2}(h)}{h^2} = 0$$ for $R_{a,2}(h) = f(a+h) - P_{a,2}(h)$

\section{Critical Points}
\paragraph{Definition} A symmetric $n \times n$ matrix A is
\begin{enumerate}
    \item \tb{positive definite} if $\tb{x}^T A \tb{x} > 0$ for all $x \in \real^n \symbol{92} \{\tb{0}\}$
    \item \tb{nonnegative definite} if $\tb{x}^T A \tb{x} \geq 0$ for all $x \in \real^n$
\end{enumerate}
In addition, we say that A is
\begin{enumerate}
    \item \tb{negative definite} if -A is positive definite
    \item \tb{nonpositive definite} if -A is nonnegative definite
\end{enumerate}
A matrix A is \tb{indefinite} if none of the above holds. Equivalently, A is indefinite if there exist $\tb{x, y}\in \real$ such that $\tb{x}^TA\tb{x} < 0 < \tb{y}^TA\tb{y}$
\paragraph{Theorem 1} Assume that A is a symmetric matrix. Then \newline
\begin{enumerate}
    \item A is positive definite $\iff$ all its eigenvalues are positive \newline
$\iff \exists \lambda_1 > 0$ such that $\tb{x}^TA\tb{x} \geq \lambda_1|\tb{x}|^2$ for all $\tb{x} \in \real^n $
    \item A is nonnegative definite $\iff$ all its eigenvalues are nonnegative \newline
    \item A is indefinite $\iff$ A has both positive and negative eigenvalues
\end{enumerate}
\paragraph{Remark} If A is a symmetric matrix then \newline
The smallest eigenvalue of A = $\min_{\{\tb{u}\in \real^n: |\tb{u}| = 1\}} \tb{u}^TA\tb{u}$
\paragraph{Theorem 2} For the matrix $A = \begin{pmatrix}
    \alpha & \beta \\
    \beta & \gamma 
\end{pmatrix}$,
\begin{enumerate}
    \item if $det A < 0,$ then A is indefinite
    \item if $det A > 0$, then
    \subitem if $\alpha > 0$ then A is positive definite
    \subitem if $\alpha < 0$ then A is negative definite
    \item if $det A = 0$ then at least one eigenvalue equals zero.
\end{enumerate}
\paragraph{Definition} A critical point $\tb{a}$ of $C^2$ function $\tb{f}$ is \under{degenerate} if det$(D_\tb{H}(\tb{a})) = 0$
\paragraph{Theorem 3 - first derivative test} If $\tb{f}: S \in \real^n \rightarrow \real$ is differentiable, then every local extremum is a critical point.
\paragraph{Theorem 4 - second derivative test}
\begin{enumerate}
    \item If $f: S \rightarrow \real$ is $C^2$ and \tb{a} is a local minimum point for $f$, then \tb{a} is a critical point of $f$ and $H(\tb{a})$ is nonnegative definite.
    \item If \tb{a} is a critical point and $H(\tb{a})$ is positive definite, then \tb{a} is a local minimum point.
\end{enumerate}
\paragraph{Corollary} Assume that $f$ is $C^2$ and $\nabla f(\tb{a}) = \tb{0}$
\begin{enumerate}
    \item If H(a) is positive definite, then a is a local min;
    \item If H(a) is negative definite, then a is a local max;
    \item If H(a) is indefinite, then a is a saddle point;
    \item If none of the above hold, then we cannot determine the character of the critical point without further thought.
\end{enumerate} 

\paragraph{E.Knight's approach to critical points.}In solving a question of $f:\real^2 \rightarrow{} \real$ we could use the following ``quick check" approach:
\begin{enumerate}
    \item Calculate the gradient of $F$, equating it to zero to find the critical points
    \item Calculate the Hessian of $F$, find the correspnding matrices for each critical points, where the Hessian is defined as
    \begin{equation*} H(f) = 
        \begin{bmatrix}
             \partial_{xx}f & \partial_{xy}f = \partial_{yx}f \\
             \partial_{xy}f = \partial_{yx}f & \partial_{yy}f
        \end{bmatrix}
    \end{equation*}
    \item Calculate the determinant of the hessian, and there are the following cases to consider
    \begin{enumerate}
        \item det$H<0$, then $sig(H) = (1,1)$ and the point is a saddle point
        \item det$H>0$, then
            \begin{enumerate}
                \item $tr(H)<0 \implies sig(H) = (2,0)$ and the point is a local minimum
                \item $tr(H)>0 \implies sig(H) = (0,2)$ and the point is a local maximum
            \end{enumerate}
        \item det$H=0$, then the test is inconclusive. We have to do this case by starring at it.
    \end{enumerate}
\end{enumerate}

\section{The Implicit Function Theorem}
Assume that S is an open subset of $\real^{n+k}$ and that $F: S \rightarrow \real^k$ is a function of class $C^1$. Assume also that $(\tb{a}, \tb{b})$ is a point in S such that $\tb{F(a, b)=0}$ and det$D_{\tb{y}}\tb{F(a, b)} \neq 0$ \newline
1. Then there exists $r_0, r_1 > 0$ such that for every $\tb{x} \in \real^n$ such that $|\tb{x} - \tb{a}| < r_0$, there exists a unique $\tb{y} \in \real^k$ such that $|\tb{y} - \tb{b}| < r_1$
    $$\tb{F(x, y) = 0} (1)$$
    In other words, equation (1) implicitly defines a function $\tb{y = f(x)}$ for $x \in \real^n$ near \tb{a}, with \tb{y = f(x)} close to \tb{b}. Note in particular that \tb{b = f(a)}. \newline
2. Moreover, the function $\tb{f}: B(r_0,\tb{a}) \rightarrow B(r_1, \tb{b}) \subset \real^k$ from part (1) above is of class $C^1$, and its derivatives may be determined by differentiating the identity $$\tb{F(x,f(x)) = 0}$$ and solving to find the partial derivatives of \tb{f}.
\paragraph{Remark} $$D\tb{f(a)} = -[D_\tb{y}\tb{F(a, b)}]^{-1}D_\tb{x}\tb{F(a, b)}$$
\section{The Inverse Function Theorem} Let U and V be open sets in $\real^n$, and assume that $\func{f}{U}{V}$ is a mapping of class $C^1$. \newline
Assume that \tb{a} $\in U$ is a point such that $D\tb{f(a)}$ is invertible. \newline
and let $\tb{b} := \tb{f(a)}$. Then there exist open sets $M \subset U$ and $N \subset V$ such that
\begin{enumerate}
    \item $\tb{a} \in M$ and $\tb{b} \in N$
    \item $\tb{f}$ is one-to-one from M onto N (hence invertible), and
    \item the inverse function $f^{-1}: N \rightarrow M$ is of class $C^1$
\end{enumerate}
Moreover, if $x \in M$ and $y = \tb{f(x)}\in N$, then $$D(\tb{f}^{-1})(\tb{y}) = [D\tb{f(x)}]^{-1}$$
In particular, $$D(\tb{f}^{-1})(\tb{b}) = [D\tb{f(a)}]^{-1}$$

\section{Some Important Coordinate Systems}
\subsection{Polar Coordinates in $\real^2$}
$$\begin{pmatrix}
    x\\y
\end{pmatrix}
= \begin{pmatrix}
    r\cos{\theta}\\
    r\sin{\theta}
\end{pmatrix}
= \tb{f}(r, \theta) $$
For \tb{f} to be a bijection between open sets, we have to restrict its domain and range. A common choice is to specify that \tb{f} is a function $U \rightarrow V$ where
$$U := \{(r, \theta): r > 0, |\theta| < \pi\},   V:= \real^2 \symbol{92}\{(x, 0): x \leq 0 \}$$
(Note that there is a half of the x-axis missing)
\subsection{Spherical Coordinates in $\real^3$}
$$\begin{pmatrix}
    x\\y\\z
\end{pmatrix}
= \begin{pmatrix}
    r\cos{\theta}\sin{\varphi}\\
    r\sin{\theta}\sin{\varphi}\\
    r\cos{\varphi}
\end{pmatrix}
= \tb{f}(r, \theta, \varphi)$$
If we want \tb{f} to be a bijection between open sets U and V, it is necessary to restrict the domain and range in some appropriate way.

\subsection{Cylindrical Coordinates in $\real^3$}
$$\begin{pmatrix}
    x\\y\\z
\end{pmatrix}
= \begin{pmatrix}
    r\cos{\theta}\\
    r\sin{\theta}\\
    z
\end{pmatrix}
= \tb{f}(r, \theta, z)$$

\section{k-Dimensional Manifolds in $\real^n$}
\subsection{The General Case}
Fix $k < n$. For a k-dimensional manifold $M$ in $\real^n$, we say that $M$ has "degrees of freedom" $k$. There are 3 natural ways to represent $M$ (be careful with the dimensions!!! ):
\paragraph{1. As a \tb{graph}:}
        $$\func{f}{U \subset \real^k}{\real^{n-k}}$$ where U is open.
        $$ S = \{(\tb{x}, \tb{f}(\tb{x})) \in \real^n: \tb{x} = \tb{f}(\tb{x}), \forall \tb{x} \in U \}$$
\paragraph{2. As a \tb{level set}:}
    $$ \func{F}{U\in \real^n}{\real^{n-k}}$$ where U is open.
    $$ S = \{\tb{x} \in U: \tb{F}(\tb{x}) = c\}$$ for some $c \in \real$.\newline
    This is also called the \ti{"zero locus"} of \tb{F} when $c = 0$
\paragraph{Remark} The regularity conditions that guarantees that S is smooth is that
\begin{enumerate}
    \item $\nabla F_1(\tb{x}), ..., \nabla F_{n-k}(\tb{x})$ are linearly independent at each $\tb{x} \in S$. Or equivalently,
    \item the matrix $D\tb{F}(\tb{x})$ has rank $n-k$ at every $\tb{x} \in S$.
\end{enumerate}
\paragraph{3. Parametrically}
$$\func{f}{U \subset \real^k}{\real^{n}}$$ where U is open.
$$ S = \{\tb{f}(\tb{u}): \tb{u} \in U\}$$
\paragraph{Remark} The regularity conditions that guarantees that S is smooth is that
\begin{enumerate}
    \item $\partial_{u_1}\tb{f}(\tb{u}),...,\partial_{u_k}\tb{f}(\tb{u})$ are linearly independent at each $\tb{u} \in U$. Or equivalently,
    \item the matrix $D\tb{f}(\tb{u})$ has rank $k$ at every $\tb{u} \in U$.
\end{enumerate}
\paragraph{Notes} We can prove that if the above conditions are satisfied, then S is smooth. Construct $\func{F}{\real^{2k}}{\real^k}$, then use IFT (the proof is hard but worthwhile to think about since the general case implies every specific case).

\subsection{The Specific Cases}
\paragraph{Theorem 1 - When is a curve regular?}
Assume that $\func{F}{\real^2}{\real}$ is $C^1$, and let
$$S:=\{\tb{x} \in \real^2: F(\tb{x}) = 0 \}$$
If $\tb{a} \in S$ and $\nabla F(\tb{a}) \neq 0$, then there exists some $r>0$ such that $B(r, \tb{a}) \cap S$ is a $C^1$ graph. \newline
(Prove directly using IFT)
\paragraph{Theorem 2 - When is the parametrization regular?} 
Assume that $\func{f}{(a, b)}{\real ^2}$ is $C^1$, and let
$$S:=\{ \tb{f}(t): t \in (a, b)\}$$
If $\tb{f}'(c) \neq 0$ for some $c \in (a, b)$, then there exists some $r>0$ such that $\{ \tb{f} (t): |t-c| < r\}$ is a $C^1$ graph. \newline
\paragraph{Remark}
It says only that the parametrization is regular near $t = c$, it does not say that S is regular near \tb{f}(c). What it means is that when increasing/decreasing t, we have no control over the path of $f(t)$.
\paragraph{Theorem 3- When is a surface regular?}
conditions: $\tb{a} \in S$ and $\nabla F(\tb{a}) \neq 0$
\paragraph{Theorem 4 - When is the parametrization regular?}
conditions: $D\tb{f}(\tb{c})$ has rank 2 at some $c$

\subsection{Remarks on smoothness of a parametric smooth curve} 
\paragraph{Definition.}If $I\subseteq \real$ is an interval, a $\mathcal{C}^1$ map $\gamma: I \rightarrow{} \real^2$ is said to be
\begin{enumerate}
    \item A \textit{regular curve} if $\gamma'(t)\neq 0, \forall t\in I$
    \item A \textit{simple curve} if $\gamma$ is injective on the interior of $I$.
\end{enumerate}
Hence if $\gamma$ is regular, then there is a neighbourhood if each point whose image looks like a graph of a $\mathcal{C}^1$-function. Simplicity guarantees that no funny overlaps can happen, and this is what is need for the curve to be smooth. Equivalently we could also convert such parametrization into a zero locus of a $F$ to use the good old method of gradient directly.


\section{Zero content}
\paragraph{Zero content in 1-D} A set $S\subset \real$ is said to have zero content if
\begin{equation*}
    \forall \epsilon > 0, \exists~\text{intervals}~I_1,...,I_n ~s.t.~ S\subseteq \bigcup_{i=1}^{n}I_i \wedge \sum_{i=1}^{n}{Len(I_i)} < \epsilon
\end{equation*}

\paragraph{Multidimensional zero content.} A set $S\subset \real^n$ is said to have zero content if
\begin{equation*}
    \forall \epsilon > 0, \exists~\text{boxes}~B_1,...,B_n~s.t.~S\subseteq \bigcup_{i=1}^{n}B_i \wedge \sum_{i=1}^{n}{Area(B_i)} < \epsilon
\end{equation*}

\paragraph{Consequence of zero content.}If a set $Z$ has zero content, then
\begin{equation*}
    \forall \epsilon>0, \exists~\text{boxes}~B_1,...,B_n~s.t.~ S\subseteq \bigcup_{i=1}^{n}B^{int}_i \wedge \sum_{i=1}^{n}{Area(B_i)} < \epsilon
\end{equation*}
Notice the extra $int$.
\section{Theorems of 1-D Integral Calculus}
\paragraph{Lemma: Refined partitions give better approximations} Let $P$ be some partition over an interval and let $P'$ be a refinement of $P$, then
\begin{equation*}
    LS_{P'}f \geq LS_{P}f \wedge US_{P'} \leq US_{P}f
\end{equation*}
Where LS and US stands for lower sum and upper sum respectively.

\paragraph{Lemma: Lower sum is always less then or equal to upper sum} If $P$ and $Q$ are any partitions of $[a,b]$, then $LS_Pf \leq US_Qf$. The essence of this proof is to consider the common refinement of these two partitions.

\paragraph{Lemma. $\epsilon-\delta$ definition of integrability} If $f$ is a bounded function on $[a,b]$, the following conditions are equivalent:
\begin{enumerate}
    \item $f$ is integrable on $[a,b]$
    \item $\forall \epsilon > 0, \exists P$ of $[a,b]$ such that $US_Pf - LS_Pf < \epsilon$
\end{enumerate}

\paragraph{Theorem:  Integration is ``Linear"}
\begin{enumerate}
    \item Suppose $a < b<c$. If $f$ is integrable on $[a,b]$ and on $[b,c]$, then $f$ is integrable on $[a,c]$, further more
    \begin{equation*}
        \int_a^c f(x)dx = \int_a^b f(x)dx + \int_b^c f(x)dx
    \end{equation*}
    \item If $f$ and $g$ are integrable on $[a,b]$, then so is $f+g$, further more
    \begin{equation*}
        \int_a^b [f(x) + g(x)]dx = \int_a^b f(x)dx + \int_a^b g(x)dx
    \end{equation*}
\end{enumerate}

\paragraph{Theorem.} Suppose $f$ is integrable on $[a,b]$.
\begin{enumerate}
    \item If $c\in \mathbb{R}$, the $cf$ is integrable on $[a,b]$, and $\int_a^b cf(x) = c\int_a^bf(x)dx$
    \item Of $[c,d] \subset [a,b]$, then $f$ is integrable on $[c,d]$.
    \item If $g$ is integrable on $[a,b]$ and $f(x) \leq g(x),\forall x \in [a,b]$, then $\int_a^b f(x)dx\leq \int_a^b g(x)dx$
    \item $|f|$ is integrable on $[a,b]$, and $\left|\int_a^bf(x)dx\right| \leq \int_a^b |f(x)|dx$
\end{enumerate}

\paragraph{Theorem: Bounded + monotone $\implies$ integrable} If $f$ is bounded and monotone on $[a,b]$, then $f$ is integrable on $[a,b]$. The proof of this uses the $\epsilon-\delta$ definition of integrability

\paragraph{Theorem: Continuous $\implies$ integrable} If $f$ is continuous on $[a,b]$, then $f$ is integrable on $[a,b]$. Note that continuous is a sufficient but not necessary condition of integrability

\paragraph{Theorem: discontinuous at only finite pts $\implies$ integrable} If $f$ is bounded on $[a,b]$ and continuous at all except finitely many points in $[a,b]$, then $f$ is integrable on $[a,b]$. A easy example of this would be any $\mathbb{R}$ function that has a hole in it.

\paragraph{Theorem: Discontinuous at only zero content $\implies$ integrable} If $f$ is bounded on $[a,b]$ and the set of points in $[a,b]$ at which $f$ is discontinuous has zero content, then $f$ is integrable on $[a,b]$.

\paragraph{Proposition.} Suppose $f$ and $g$ are integrable on $[a,b]$ and $f(x) = g(x)$ for all except finitely many points $x\in [a,b]$. Then $\int_a^bf(x)dx = \int_a^bg(x)dx$. 

\paragraph{The Fundamental Theorem Of Calculus}
\begin{enumerate}
    \item Let $f$ be an integrable function on $[a,b]$. For $x\in [a,b]$, let $F(x) = \int_a^xf(t)dt$. Then $F$ is continuous on $[a,b]$; more-over, $F'(x)$ exists and equals $f(x)$ at every $x$ at which $f$ is continuous,
    \item Let $F$ be a continuous function on $[a,b]$ that is differentiable except perhaps at finitely many points in $[a,b]$, and let $f$ be a function on $[a,b]$ that agrees with $F'$ at all points where the latter is defined. If $f$ is integrable on $[a,b]$, then $\int_a^bf(t)dt=F(b)-F(a)$
\end{enumerate}

\paragraph{Proposition.} Suppose $f$ is integrable on $[a,b]$. Given $\epsilon>0, \exists \delta > 0$ such that if $P= \{x_0,...,x_J\}$ is any partition of $[a,b]$ satisfying
\begin{equation*}
    max\{x_j-x_{j-1} | 1\leq j \leq J\} < \delta
\end{equation*}
the sums $LS_Pf$ and $US_Pf$ differ from $\int_a^bf(x)dx$ by at most $\epsilon$.

\section{Generalized Integral Calculus}
\paragraph{Theorems of double integrals}
\begin{enumerate}
    \item If $f_1$ and $f_2$ are integrable on the bounded set $S$ and $c_1,c_2\in \real$, then $c_1f_1 + c_2f_2$ is integrable on $S$, and
    \begin{equation*}
        \iint_S[c_1f_1 + c_2f_2]dA = c_1\iint_Sf_1dA + c_2\iint_Sf_2dA
    \end{equation*}
    
    \item Let $S_1$ and $S_2$ be bounded sets with no points in common (intersection $ =\emptyset$), and let $f$ be a bounded function. If $f$ is integrable on $S_1$ and on $S_2$, then $f$ is integrable on $S_1\cup S_2$, in which case
    \begin{equation*}
        \iint_{S_1\cup S_2}fdA = \iint_{S_1}fdA + \iint_{S_2} fdA
    \end{equation*}
    
    \item If $f$ and $g$ are integrable on $S$ and $f(\mathbf{x})\leq g(\mathbf{x})$ for $\bx \in S$, then $\iint_S fdA \leq \iint_S g dA$
    
    \item If $f$ is integrable on $S$, then so is $|f|$, and
    \begin{equation*}
        \left|\iint_Sf dA\right| \leq \iint_S|f|dA
    \end{equation*}
\end{enumerate}

\paragraph{Theorem.} Suppose $f$ is a bounded function on the rectangle $R$. If the set of points in $R$ at which $f$ is discontinuous has zero content, then f is integrable on $R$.

\paragraph{Proposition: on zero content} 
\begin{enumerate}
    \item If $Z\subset \real^2$ has zero content and $U\subset Z$, then $U$ has zero content.
    \item If $Z_1,...,Z_k$ have zero content, then so does $\bigcup_1^k Z_j$
    \item $\mathbf{f}:(a_0, b_0) \xrightarrow{} \real^2$ is of class $C_1$, then $\mathbf{f}([a,b])$ has zero content whenever $a_0<a<b<b_0$
\end{enumerate}

\paragraph{Discontinuity of characteristic function} The function $\chi_S$ is discontinuous at $\bx$ if and only if $\bx$ is in the boundary of $S$.

\paragraph{Theorem.} Let $S$ be a measurable subset of $\real^2$. Suppose $f:{\real^2} \rightarrow{}{\real}$ is bounded and the set of points in $S$ at which $f$ is discontinuous has zero content. Then $f$ is integrable on $S$. 
\paragraph{Remark on this theorem:} The only points where $f_{\chi_S}$ can be discontinuous are those points in the closure of S where either $f$ or $\chi_S$ is discontinuous. Both of these cases are discontuinity on a set of zero content. And we can definitely fix $S$ inside of a rectangle, then by the previously stated theorem (The theorem directly above), such function is integrable.

\paragraph{Proposition: Integration on a set of zero content evaluates to zero.} Suppose $Z\subset \real^2$ has zero content. If $f:\real^2\rightarrow{} \real$ is bounded, then $f$ is integrable on $Z$ and $\int_Z fdA = 0$

\paragraph{Corollary}
\begin{enumerate}
    \item Suppose that $f$ is integrable on the set $S\subset \real^2$. If $g(\bx) = f(\bx)$ except for $\bx$ in a set of zero content, then $g$ is integrable on $S$ and $\int_S gdA = \int_S fdA$
    \item Suppose that $f$ is integrable on $S$ and on $T$, and $S\cap T$ has zero content. Then $f$ is integrable on $S\cup T$, and $\int_{S\cup T}fdA = \int_Sfd+ \int_TfdA$
\end{enumerate}
 
\end{document}

